{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Flatten, Dense, Activation, MaxPooling2D, Dropout, Input, BatchNormalization, AveragePooling2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('analog_clocks/label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(im):\n",
    "    \n",
    "    im = im/255\n",
    "    im -= .5\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 1\n",
    "im_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_batch(ids, batch_size=32):\n",
    "    \n",
    "    path = 'analog_clocks/images/'\n",
    "    image_batch = np.zeros((batch_size, im_size, im_size, channel))\n",
    "    \n",
    "    label_hour = np.zeros((batch_size, 1))\n",
    "    label_min = np.zeros((batch_size, 1))\n",
    "    batch_ids = np.random.choice(ids, batch_size)\n",
    "    \n",
    "    ind = 0\n",
    "    for i in range(len(batch_ids)):\n",
    "        \n",
    "        if channel == 1:\n",
    "            im = Image.open(path + str(batch_ids[i]) + '.jpg').convert('L')\n",
    "        else:\n",
    "            im = Image.open(path + str(batch_ids[i]) + '.jpg')\n",
    "        im = im.resize((im_size,im_size), Image.ANTIALIAS)\n",
    "        im = np.array(im)\n",
    "        image_batch[ind] = preprocess(im).reshape((im_size, im_size, channel))\n",
    "        label_hour[ind] = (data['hour'][data.index==batch_ids[i]])\n",
    "        label_min[ind] = (data['minute'][data.index==batch_ids[i]])/60\n",
    "        ind += 1\n",
    "            \n",
    "    return (np.array(image_batch), np.array(label_hour), np.array(label_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.arange(100)\n",
    "x, y1, y2 = load_image_batch(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           (None, 100, 100, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 48, 48, 50)   1300        input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling2D) (None, 24, 24, 50)   0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 24, 24, 50)   200         max_pooling2d_84[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 22, 22, 100)  45100       batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling2D) (None, 11, 11, 100)  0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 11, 11, 100)  400         max_pooling2d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 9, 9, 150)    135150      batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling2D) (None, 4, 4, 150)    0           conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 150)    600         max_pooling2d_86[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 2, 2, 200)    270200      batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 2, 2, 200)    0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 800)          0           dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 144)          115344      flatten_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 100)          80100       flatten_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 144)          20880       dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 200)          20200       dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hour (Dense)                    (None, 12)           1740        dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "minute (Dense)                  (None, 1)            201         dense_87[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 691,415\n",
      "Trainable params: 690,815\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(im_size,im_size, channel))\n",
    "\n",
    "x = Conv2D(50, kernel_size=5, strides=2, activation='relu')(inp)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(100, kernel_size=3, strides=1, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(150, kernel_size=3, strides=1, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(200, kernel_size=3, strides=1, activation='relu')(x)\n",
    "x = Dropout(.4)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "hour = Dense(144, activation='relu')(x)\n",
    "hour = Dense(144, activation='relu')(hour)\n",
    "hour = Dense(12, activation='softmax', name='hour')(hour)\n",
    "\n",
    "minute = Dense(100, activation='relu')(x)\n",
    "minute = Dense(200, activation='relu')(minute)\n",
    "minute = Dense(1, activation='linear', name='minute')(minute)\n",
    "\n",
    "model = Model(inputs=inp, outputs=[hour, minute])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y1, y2 = x_, y1_, y2_\n",
    "x1, z1, z2 = x1_, z1_, z2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.arange(40000)\n",
    "test_ids = np.arange(10000) + 40000\n",
    "\n",
    "x_, y1_, y2_ = load_image_batch(train_ids, 40000)\n",
    "\n",
    "x1_, z1_, z2_ = load_image_batch(test_ids, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.adam(lr=.00001)\n",
    "model.compile(loss=['sparse_categorical_crossentropy', 'mse'], optimizer=adam, metrics=['accuracy', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 15s 376us/step - loss: 0.0112 - hour_loss: 0.0025 - minute_loss: 0.0086 - hour_acc: 0.9994 - hour_mean_absolute_error: 5.4811 - minute_acc: 0.0160 - minute_mean_absolute_error: 0.0683 - val_loss: 0.0577 - val_hour_loss: 0.0480 - val_minute_loss: 0.0097 - val_hour_acc: 0.9900 - val_hour_mean_absolute_error: 5.1767 - val_minute_acc: 0.0300 - val_minute_mean_absolute_error: 0.0691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a49ed6198>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, [y1, y2], epochs=1, batch_size=256, validation_data=(x1, [z1, z2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
